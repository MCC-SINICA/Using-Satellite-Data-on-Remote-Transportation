{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test oceanwind code with degenerations\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import threading\n",
    "import argparse\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import sklearn.metrics as metrics\n",
    "import math\n",
    "import time\n",
    "import gc\n",
    "from datetime import datetime\n",
    "from collections import Iterable\n",
    "from tensorflow.keras import losses\n",
    "from statistics import mean\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow.python.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import TensorBoard,ModelCheckpoint, EarlyStopping,Callback\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from tensorflow.keras.optimizers import *\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "n_classes = 18\n",
    "time_step1 = 3\n",
    "#optim = Adam(lr = 0.0001)\n",
    "#optim = Adam(lr = 0.00001, decay = 0.00001)\n",
    "optim = Adam(learning_rate = 1e-4)\n",
    "#sample_batch = 16\n",
    "sample_batch = 10\n",
    "number_stations = 18\n",
    "NB_epoch = 650\n",
    "\n",
    "def eval_metrics_on(predictions,labels):\n",
    "    '''assuming this is a regression task; labels are continuous-valued floats\n",
    "    \n",
    "    returns most regression-related scores for the given predictions/targets as a dictionary:\n",
    "    \n",
    "        r2, mean_abs_error, mse, rmse, median_absolute_error, explained_variance_score\n",
    "    '''\n",
    "    #if len(labels[0])==2: #labels is list of data/labels pairs\n",
    "        #labels = np.concatenate([l[1] for l in labels])\n",
    "    #predictions = predictions[:,0]\n",
    "    prdictions = np.array(predictions)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    r2                       = metrics.r2_score(labels, predictions)\n",
    "    mean_abs_error           = np.abs(predictions - labels).mean()\n",
    "    mse                      = ((predictions - labels)**2).mean()\n",
    "    rmse                     = np.sqrt(mse)\n",
    "    #median_absolute_error    = metrics.median_absolute_error(labels, predictions) # robust to outliers\n",
    "    explained_variance_score = metrics.explained_variance_score(labels, predictions) # best score = 1, lower is worse\n",
    "    return {'r2':r2, 'mean_abs_error':mean_abs_error, 'mse':mse, 'rmse':rmse, \n",
    "    'explained_variance_score':explained_variance_score}\n",
    "\n",
    "\n",
    "def predict_graph(true_val,predict_val):\n",
    "    for sn in range(number_stations):\n",
    "        plt.figure(figsize=(6,3))\n",
    "        plt.figure(sn+1)\n",
    "        plt.title('_next_12hour station = ' + str(sn+1))\n",
    "        plt.plot(true_val[:,sn::number_stations], c='g', label= 'gt')\n",
    "        plt.plot(predict_val[:,sn::number_stations], c='r', label= 'pred')\n",
    "        plt.legend(loc='best',prop={'size': 5})\n",
    "        plt.legend(loc='best')\n",
    "        name = str(\"firstgroup_stat_\") + str(sn) + str(\".png\")\n",
    "        #plt.savefig(name)\n",
    "        plt.show()\n",
    "        \n",
    "class ClearMemory(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        gc.collect()\n",
    "        K.clear_session()\n",
    "            \n",
    "#extracted remote features\n",
    "data_shape1 = (3,11720)\n",
    "in1 = Input(shape=data_shape1)\n",
    "#model1 = fn_model_schw(in1)\n",
    "\n",
    "# local Pm2.5\n",
    "data_shape2 = (1,18)\n",
    "in2 = Input(shape=data_shape2)\n",
    "\n",
    "#local weather\n",
    "localweather_data_shape3 = (1,90)\n",
    "in3 = Input(shape=localweather_data_shape3)\n",
    "\n",
    "\n",
    "weather_in = Flatten()(in3)\n",
    "weather_in = RepeatVector(time_step1)(weather_in)\n",
    "\n",
    "pm_in = Flatten()(in2)\n",
    "pm_in = RepeatVector(time_step1)(pm_in)\n",
    "\n",
    "model_final_concat = concatenate([in1,pm_in,weather_in])\n",
    "\n",
    "\n",
    "model_final_concat = TimeDistributed(Dense(52, activation='relu'))(model_final_concat)\n",
    "#model_final_concat = Dense(128, activation='relu',bias_regularizer=L1L2(l1 = 0.01,l2=0.01))(model_final_concat)\n",
    "model_final_concat = TimeDistributed(Dropout(rate = 0.5))(model_final_concat)\n",
    "#model_final_concat = BatchNormalization()(model_final_concat)\n",
    "#model_final_concat = Dense(64, activation='relu',bias_regularizer=L1L2(l1 = 0.01,l2=0.01))(model_final_concat)\n",
    "model_final_concat = TimeDistributed(Dense(42, activation='relu'))(model_final_concat)\n",
    "model_final_concat = TimeDistributed(Dropout(rate=0.5))(model_final_concat)\n",
    "#model_final_concat = Dropout(rate=0.3)(model_final_concat)\n",
    "\n",
    "model_final_concat = TimeDistributed(Dense(n_classes))(model_final_concat)\n",
    "\n",
    "\n",
    "model = Model(inputs=[in1,in2,in3],outputs=model_final_concat)\n",
    "\n",
    "model.summary()\n",
    "                      \n",
    "\n",
    "aod_train = np.load('middlelayer_train_3day_4tile.npy').astype('float')\n",
    "aod_valid = np.load('middlelayer16_3day_4tile.npy').astype('float')\n",
    "\n",
    "local_weather_train14 = np.load('local_weather_yr14_n3day_train.npy').astype('float')\n",
    "local_weather_train15 = np.load('local_weather_yr15_n3day_train.npy').astype('float')\n",
    "local_weather_train = np.concatenate((local_weather_train14,local_weather_train15),axis = 0)\n",
    "\n",
    "local_weather_train = local_weather_train.reshape(local_weather_train.shape[0],local_weather_train.shape[1],\n",
    "                                                  local_weather_train.shape[2]*local_weather_train.shape[3])\n",
    "\n",
    "local_pm = np.load('pm_n3day_daily_train.npy')[:-6].astype('float')\n",
    "tru_val = np.load('pm_label_n3day_daily_train.npy')[:-6].astype('float')\n",
    "\n",
    "local_weather_test = np.load('local_weather_n3day_test.npy').astype('float')\n",
    "local_weather_test = local_weather_test.reshape(local_weather_test.shape[0],local_weather_test.shape[1],\n",
    "                                                local_weather_test.shape[2]*local_weather_test.shape[3])\n",
    "\n",
    "local_pm_test = np.load('pm_n3day_daily_valid.npy')[:-4].astype('float')\n",
    "tru_val_test = np.load('pm_label_n3day_valid_daily.npy')[:-4].astype('float')\n",
    "\n",
    "\n",
    "model.compile(optimizer = optim, loss = 'mse', metrics = ['mse'], run_eagerly=True)\n",
    "\n",
    "keras_callback = [\n",
    "                EarlyStopping(monitor='val_mse', patience = 90, mode='min'),\n",
    "                ModelCheckpoint(filepath='next3day_strip_model.h5', monitor='val_mse', \n",
    "                save_best_only=True,mode='min',verbose=1)\n",
    "                ]\n",
    "\n",
    "\n",
    "history = model.fit([aod_train,local_pm,local_weather_train[:-6]],\n",
    "                            tru_val,batch_size = sample_batch,\n",
    "                            epochs = NB_epoch,verbose = 1,shuffle = False,callbacks=keras_callback,\n",
    "            validation_data = ([aod_valid,local_pm_test,local_weather_test[:-4]],\n",
    "                                tru_val_test))\n",
    "\n",
    "\n",
    "#summarize histoy for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'],loc = 'upper left')\n",
    "plt.show()\n",
    "\n",
    "print('this is val_mse')\n",
    "plt.plot(history.history['mse'])\n",
    "plt.plot(history.history['val_mse'])\n",
    "plt.title('model mse')\n",
    "plt.ylabel('mse')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'],loc = 'upper left')\n",
    "plt.show()                      \n",
    "\n",
    "predictions_edit = model.predict([aod_valid,local_pm_test,local_weather_test[:-4]],\n",
    "                            batch_size = sample_batch, verbose=1)\n",
    "\n",
    "predictions = predictions_edit.reshape(predictions_edit.shape[0]*predictions_edit.shape[1],predictions_edit.shape[2])\n",
    "print(predictions_edit.shape)\n",
    "y_label = np.load('pm_label_n3day_valid_daily.npy')[:-4].astype(\"float\")\n",
    "y_label2 = y_label.reshape(y_label.shape[0]*y_label.shape[1],y_label.shape[2])\n",
    "print('shape of true and predict ',y_label2.shape,predictions.shape)\n",
    "\n",
    "#perform model evaluation\n",
    "eval_results = eval_metrics_on(predictions,y_label2)\n",
    "print('this is evaluation results for r2,mean_abs_error,mse,rmse,expl_var_score ',eval_results)\n",
    "#print('this is evaluation results for r2,mean_abs_error,mse,rmse,expl_var_score ',eval_results)\n",
    "\n",
    "#observe the graph between prediction and true value of PM2.5 for last hour\n",
    "y_true = y_label[:,2:3,:]\n",
    "y_true = y_true.reshape(y_true.shape[0]*y_true.shape[1],y_true.shape[2])\n",
    "pred_graph = predictions_edit[:,0:1,:]\n",
    "pred_graph =pred_graph.reshape(pred_graph.shape[0]*pred_graph.shape[1],pred_graph.shape[2])\n",
    "predict_graph(y_true,pred_graph)\n",
    "\n",
    "print('rmse value')\n",
    "stat_dict = {}\n",
    "stat_avg = []\n",
    "for i in range(time_step1):\n",
    "    t1 = predictions_edit[:,i:i+1,:]\n",
    "    t1 = t1.reshape(t1.shape[0]*t1.shape[1],t1.shape[2])\n",
    "    t2 = y_label[:,i:i+1,:]\n",
    "    t2 = t2.reshape(t2.shape[0]*t2.shape[1],t2.shape[2])\n",
    "    rsl = []\n",
    "    for sn in range(number_stations):\n",
    "        name = 'stats_' + str(sn)\n",
    "        score2 = np.sqrt(np.mean(np.square(t1[:,sn::number_stations]-t2[:,sn::number_stations])))\n",
    "        stat_dict.setdefault(name,[]).append(score2)\n",
    "        #print(score2)\n",
    "        rsl.append(score2)\n",
    "for k in  stat_dict.keys():\n",
    "    avg_value = sum(stat_dict[k])/time_step1\n",
    "    #print(avg_value)\n",
    "    stat_avg.append(avg_value)\n",
    "print('mean of all stations ',mean(stat_avg))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PERFORM PREDICTION USING BEST SAVED MODEL THEN SAVE THAT PREDICTION RESULTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_model('next3day_strip_model.h5')\n",
    "predictions_edit2 = model2.predict([aod_valid,local_pm_test,local_weather_test[:-4]],\n",
    "                            batch_size = sample_batch, verbose=1)\n",
    "\n",
    "predictions = predictions_edit2.reshape(predictions_edit2.shape[0]*predictions_edit2.shape[1],predictions_edit2.shape[2])\n",
    "print(predictions_edit2.shape)\n",
    "print('shape of true and predict ',y_label2.shape,predictions.shape)\n",
    "\n",
    "#perform model evaluation\n",
    "eval_results = eval_metrics_on(predictions,y_label2)\n",
    "print('this is evaluation results for r2,mean_abs_error,mse,rmse,expl_var_score ',eval_results)\n",
    "#print('this is evaluation results for r2,mean_abs_error,mse,rmse,expl_var_score ',eval_results)\n",
    "\n",
    "#observe the graph between prediction and true value of PM2.5 for last hour\n",
    "y_true = y_label[:,2:3,:]\n",
    "y_true = y_true.reshape(y_true.shape[0]*y_true.shape[1],y_true.shape[2])\n",
    "pred_graph = predictions_edit[:,2:3,:]\n",
    "pred_graph =pred_graph.reshape(pred_graph.shape[0]*pred_graph.shape[1],pred_graph.shape[2])\n",
    "predict_graph(y_true,pred_graph)\n",
    "\n",
    "print('rmse value')\n",
    "stat_dict = {}\n",
    "stat_avg = []\n",
    "for i in range(time_step1):\n",
    "    t1 = predictions_edit2[:,i:i+1,:]\n",
    "    t1 = t1.reshape(t1.shape[0]*t1.shape[1],t1.shape[2])\n",
    "    t2 = y_label[:,i:i+1,:]\n",
    "    t2 = t2.reshape(t2.shape[0]*t2.shape[1],t2.shape[2])\n",
    "    rsl = []\n",
    "    for sn in range(number_stations):\n",
    "        name = 'stats_' + str(sn)\n",
    "        score2 = np.sqrt(np.mean(np.square(t1[:,sn::number_stations]-t2[:,sn::number_stations])))\n",
    "        stat_dict.setdefault(name,[]).append(score2)\n",
    "        #print(score2)\n",
    "        rsl.append(score2)\n",
    "for k in  stat_dict.keys():\n",
    "    avg_value = sum(stat_dict[k])/time_step1\n",
    "    #print(avg_value)\n",
    "    stat_avg.append(avg_value)\n",
    "print('mean of all stations ',mean(stat_avg))\n",
    "\n",
    "#save the prediction reuslts\n",
    "np.save('strip_4tilepredresults_next3day.npy',predictions_edit2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PERFORM PREDICTION USING BEST SAVED MODEL ON TRAIN DATASE YEAR 2014 THEN SAVE THAT PREDICTION RESULTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "\n",
    "import threading\n",
    "import argparse\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import gc\n",
    "from collections import Iterable\n",
    "from tensorflow.keras import losses\n",
    "from statistics import mean\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow.python.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import TensorBoard,ModelCheckpoint, EarlyStopping,Callback\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from tensorflow.keras.optimizers import *\n",
    "#K.set_image_data_format('channels_first')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "n_classes = 18\n",
    "time_step = 3\n",
    "#optim = Adam(lr = 0.0001)\n",
    "#optim = Adam(lr = 0.00001, decay = 0.00001)\n",
    "optim = Adam(learning_rate = 1e-4)\n",
    "#sample_batch = 16\n",
    "sample_batch = 10\n",
    "number_stations = 18\n",
    "\n",
    "\n",
    "class ClearMemory(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        gc.collect()\n",
    "        K.clear_session()\n",
    "        \n",
    "        \n",
    "        \n",
    "aod_train = np.load('middlelayer_train_3day_4tile.npy')[0:350].astype('float')\n",
    "\n",
    "local_weather_train14 = np.load('local_weather_yr14_n3day_train.npy').astype('float')\n",
    "\n",
    "local_weather_train14 = local_weather_train14.reshape(local_weather_train14.shape[0],local_weather_train14.shape[1],\n",
    "                                                  local_weather_train14.shape[2]*local_weather_train14.shape[3])\n",
    "\n",
    "local_pm = np.load('pm_n3day_daily_train.npy')[0:353].astype('float')\n",
    "tru_val = np.load('pm_label_n3day_daily_train.npy')[0:353].astype('float')\n",
    "\n",
    "model2 = load_model('next3day_strip_model.h5')\n",
    "predictions_edit2 = model2.predict([aod_train,local_pm[:-3],local_weather_train14[:-3]],\n",
    "                            batch_size = sample_batch, verbose=1)\n",
    "\n",
    "\n",
    "print(predictions_edit2.shape)\n",
    "\n",
    "np.save('strip_4tilepredresults_2014_next3day.npy',predictions_edit2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PERFORM PREDICTION USING BEST SAVED MODEL ON TRAIN DATASE YEAR 2015 THEN SAVE THAT PREDICTION RESULTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "\n",
    "import threading\n",
    "import argparse\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import gc\n",
    "from collections import Iterable\n",
    "from tensorflow.keras import losses\n",
    "from statistics import mean\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow.python.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import TensorBoard,ModelCheckpoint, EarlyStopping,Callback\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from tensorflow.keras.optimizers import *\n",
    "#K.set_image_data_format('channels_first')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "n_classes = 18\n",
    "time_step = 3\n",
    "#optim = Adam(lr = 0.0001)\n",
    "#optim = Adam(lr = 0.00001, decay = 0.00001)\n",
    "optim = Adam(learning_rate = 1e-4)\n",
    "#sample_batch = 16\n",
    "sample_batch = 10\n",
    "number_stations = 18\n",
    "\n",
    "\n",
    "class ClearMemory(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        gc.collect()\n",
    "        K.clear_session()\n",
    "        \n",
    "        \n",
    "        \n",
    "aod_train = np.load('middlelayer_train_3day_4tile.npy')[350:700].astype('float')\n",
    "\n",
    "local_weather_train15 = np.load('local_weather_yr15_n3day_train.npy').astype('float')\n",
    "\n",
    "local_weather_train14 = local_weather_train14.reshape(local_weather_train14.shape[0],local_weather_train14.shape[1],\n",
    "                                                  local_weather_train14.shape[2]*local_weather_train14.shape[3])\n",
    "\n",
    "local_pm = np.load('pm_n3day_daily_train.npy')[353].astype('float')\n",
    "tru_val = np.load('pm_label_n3day_daily_train.npy')[0:353].astype('float')\n",
    "\n",
    "model2 = load_model('next3day_strip_model.h5')\n",
    "predictions_edit2 = model2.predict([aod_train,local_pm[:-3],local_weather_train14[:-3]],\n",
    "                            batch_size = sample_batch, verbose=1)\n",
    "\n",
    "\n",
    "print(predictions_edit2.shape)\n",
    "\n",
    "np.save('strip_4tilepredresults_2015_next3day.npy',predictions_edit2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
